{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weak estimator\n",
    "###### Performance better than random guessing\n",
    "###### Light model\n",
    "###### Low training and evaluation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Some \"weak\" models:\n",
    "# Decision tree: small depth\n",
    "# Linear Regression\n",
    "\n",
    "# Sample code:\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=3\n",
    ")\n",
    "model = LogisticRegression(\n",
    "    max_iter=50, C=100.0\n",
    ")\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Build unrestricted decision tree\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build restricted decision tree\n",
    "clf = DecisionTreeClassifier(max_depth=4, max_features=2, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
